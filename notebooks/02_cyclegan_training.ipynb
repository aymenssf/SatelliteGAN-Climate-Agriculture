{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Entrainement du CycleGAN\n",
    "\n",
    "Ce notebook entraine un CycleGAN pour apprendre la transformation\n",
    "bidirectionnelle entre images agricoles normales et en conditions de secheresse.\n",
    "\n",
    "**Pipeline :**\n",
    "1. Preparer les donnees (domaine A = normal, domaine B = secheresse simulee)\n",
    "2. Initialiser le CycleGAN avec sauvegarde Drive\n",
    "3. Entrainer (~3-5h sur GPU T4 Colab) avec auto-resume\n",
    "4. Visualiser les resultats\n",
    "5. Sauvegarder le modele final dans Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration Google Drive pour sauvegarde outputs.\n",
    "Les notebooks restent sur GitHub, seuls les checkpoints/resultats vont dans Drive.\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Montage Drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Chemin racine pour les outputs uniquement\n",
    "DRIVE_OUTPUTS = \"/content/drive/MyDrive/SatelliteGAN-Outputs\"\n",
    "\n",
    "# Creation structure outputs\n",
    "for subdir in [\n",
    "    'data/eurosat', 'data/processed_drought',\n",
    "    'cyclegan/checkpoints', 'cyclegan/generated_images', 'cyclegan/losses',\n",
    "    'diffusion/checkpoints', 'diffusion/samples', 'diffusion/losses',\n",
    "    'evaluation/metrics', 'evaluation/comparisons', 'evaluation/figures',\n",
    "]:\n",
    "    os.makedirs(f\"{DRIVE_OUTPUTS}/{subdir}\", exist_ok=True)\n",
    "\n",
    "print(f\"Drive monte : {DRIVE_OUTPUTS}\")\n",
    "print(f\"Structure outputs creee\")\n",
    "\n",
    "# Clone du repo GitHub (code source)\n",
    "if not os.path.exists('/content/SatelliteGAN-Climate-Agriculture'):\n",
    "    !git clone https://github.com/aymenssf/SatelliteGAN-Climate-Agriculture.git /content/SatelliteGAN-Climate-Agriculture\n",
    "    !pip install -q -r /content/SatelliteGAN-Climate-Agriculture/requirements.txt\n",
    "\n",
    "%cd /content/SatelliteGAN-Climate-Agriculture\n",
    "sys.path.insert(0, '/content/SatelliteGAN-Climate-Agriculture')\n",
    "\n",
    "print(\"Code source charge depuis GitHub\")\n",
    "print(\"Outputs seront sauvegardes dans Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from src.config import DEVICE, CYCLEGAN, IMAGE_SIZE\n",
    "from src.dataset import get_agricultural_dataset, split_dataset\n",
    "from src.preprocessing import (\n",
    "    get_cyclegan_transform, get_eval_transform, \n",
    "    simulate_drought, denormalize, tensor_to_numpy\n",
    ")\n",
    "from src.cyclegan.train import CycleGANTrainer\n",
    "from src.evaluation.visualization import (\n",
    "    show_cyclegan_results, show_comparison, plot_training_losses\n",
    ")\n",
    "\n",
    "print(f\"Device : {DEVICE}\")\n",
    "print(f\"Configuration CycleGAN : {CYCLEGAN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation des donnees\n",
    "\n",
    "On cree deux domaines :\n",
    "- **Domaine A** : images agricoles normales (EuroSAT)\n",
    "- **Domaine B** : images agricoles avec secheresse simulee\n",
    "\n",
    "Le CycleGAN n'a pas besoin de paires appariees, mais on cree\n",
    "les deux domaines a partir du meme dataset pour comparer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Charger le dataset brut (sans normalisation) pour appliquer la simulation\n",
    "raw_transform = transforms.Resize(IMAGE_SIZE)\n",
    "raw_dataset = get_agricultural_dataset(transform=raw_transform)\n",
    "\n",
    "# Split\n",
    "train_set, val_set, _ = split_dataset(raw_dataset)\n",
    "\n",
    "print(f\"Images d'entrainement : {len(train_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer les tensors pour les deux domaines\n",
    "cyclegan_transform = get_cyclegan_transform()\n",
    "eval_transform = get_eval_transform()\n",
    "\n",
    "def prepare_paired_batch(dataset, transform, n_max=None):\n",
    "    \"\"\"\n",
    "    Prepare les batches pour le CycleGAN.\n",
    "    Domaine A = images normales normalisees\n",
    "    Domaine B = images secheresse normalisees\n",
    "    \"\"\"\n",
    "    images_a = []\n",
    "    images_b = []\n",
    "    n = min(len(dataset), n_max) if n_max else len(dataset)\n",
    "    \n",
    "    for i in range(n):\n",
    "        img, _ = dataset[i]\n",
    "        \n",
    "        # Convertir en PIL si c'est un tensor\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img_pil = transforms.ToPILImage()(img)\n",
    "        else:\n",
    "            img_pil = img\n",
    "        \n",
    "        # Domaine A : normal\n",
    "        img_a = transform(img_pil)\n",
    "        \n",
    "        # Domaine B : secheresse simulee\n",
    "        drought_pil = simulate_drought(img_pil, severity=0.6)\n",
    "        img_b = transform(drought_pil)\n",
    "        \n",
    "        images_a.append(img_a)\n",
    "        images_b.append(img_b)\n",
    "    \n",
    "    return torch.stack(images_a), torch.stack(images_b)\n",
    "\n",
    "print(\"Preparation des donnees d'entrainement...\")\n",
    "train_a, train_b = prepare_paired_batch(train_set, cyclegan_transform)\n",
    "print(f\"Domaine A : {train_a.shape}\")\n",
    "print(f\"Domaine B : {train_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le DataLoader\n",
    "train_dataset = TensorDataset(train_a, train_b)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CYCLEGAN['batch_size'], \n",
    "    shuffle=True, \n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(f\"Nombre de batches par epoch : {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialisation du CycleGAN\n",
    "\n",
    "Le `save_dir` pointe vers Google Drive pour que les checkpoints,\n",
    "images generees et historique des pertes survivent aux deconnexions Colab.\n",
    "\n",
    "Si un checkpoint existe deja dans Drive, l'entrainement reprend\n",
    "automatiquement depuis le dernier checkpoint (auto-resume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le trainer avec sauvegarde Drive\n",
    "trainer = CycleGANTrainer(\n",
    "    save_dir=f\"{DRIVE_OUTPUTS}/cyclegan\"  # Checkpoints, images, pertes -> Drive\n",
    ")\n",
    "\n",
    "# Compter les parametres\n",
    "n_params_G = sum(p.numel() for p in trainer.G_A2B.parameters())\n",
    "n_params_D = sum(p.numel() for p in trainer.D_A.parameters())\n",
    "print(f\"Parametres Generateur : {n_params_G:,}\")\n",
    "print(f\"Parametres Discriminateur : {n_params_D:,}\")\n",
    "print(f\"Total : {2*n_params_G + 2*n_params_D:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrainement\n",
    "\n",
    "L'entrainement alterne entre les generateurs et les discriminateurs.\n",
    "Le replay buffer stabilise l'entrainement.\n",
    "\n",
    "**Sauvegarde automatique :**\n",
    "- Checkpoints tous les 10 epochs dans `Drive/SatelliteGAN-Outputs/cyclegan/checkpoints/`\n",
    "- Images A->B et B->A dans `Drive/SatelliteGAN-Outputs/cyclegan/generated_images/`\n",
    "- Historique pertes (JSON) dans `Drive/SatelliteGAN-Outputs/cyclegan/losses/`\n",
    "\n",
    "**Auto-resume :** si l'entrainement est interrompu, relancer cette cellule.\n",
    "Le trainer detecte le dernier checkpoint et reprend automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "# Reduire n_epochs pour un test rapide (ex: 5-10 epochs)\n",
    "# Pour l'entrainement complet, utiliser CYCLEGAN['n_epochs'] (100)\n",
    "N_EPOCHS = CYCLEGAN['n_epochs']  # mettre 5 pour un test rapide\n",
    "\n",
    "# L'auto-resume detecte les checkpoints existants dans Drive.\n",
    "# Pour forcer une reprise depuis un checkpoint specifique :\n",
    "#   history = trainer.train(train_loader, n_epochs=N_EPOCHS,\n",
    "#                           resume_from=f\"{DRIVE_OUTPUTS}/cyclegan/checkpoints/epoch_40.pth\")\n",
    "\n",
    "history = trainer.train(train_loader, n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Courbes de perte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les courbes de perte (sauvegardees dans Drive)\n",
    "plot_training_losses(\n",
    "    history, \n",
    "    title='CycleGAN - Courbes de perte',\n",
    "    save_path=f\"{DRIVE_OUTPUTS}/evaluation/figures/cyclegan_losses.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation des resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparer quelques images de validation\n",
    "print(\"Preparation des donnees de validation...\")\n",
    "val_a, val_b = prepare_paired_batch(val_set, eval_transform, n_max=8)\n",
    "\n",
    "# Generer les transformations\n",
    "with torch.no_grad():\n",
    "    val_a_dev = val_a.to(DEVICE)\n",
    "    val_b_dev = val_b.to(DEVICE)\n",
    "    \n",
    "    fake_b = trainer.G_A2B(val_a_dev)    # Normal -> Secheresse\n",
    "    fake_a = trainer.G_B2A(val_b_dev)    # Secheresse -> Normal\n",
    "    cycle_a = trainer.G_B2A(fake_b)      # Normal -> Secheresse -> Normal\n",
    "    cycle_b = trainer.G_A2B(fake_a)      # Secheresse -> Normal -> Secheresse\n",
    "\n",
    "# Afficher les resultats complets (sauvegarde dans Drive)\n",
    "show_cyclegan_results(\n",
    "    val_a_dev.cpu(), fake_b.cpu(), cycle_a.cpu(),\n",
    "    val_b_dev.cpu(), fake_a.cpu(), cycle_b.cpu(),\n",
    "    n_samples=4,\n",
    "    save_path=f\"{DRIVE_OUTPUTS}/evaluation/comparisons/cyclegan_cycle_results.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison directe Normal vs CycleGAN secheresse\n",
    "show_comparison(\n",
    "    val_a.cpu(), fake_b.cpu(),\n",
    "    n_samples=6,\n",
    "    labels=('Normal (reel)', 'Secheresse (CycleGAN)'),\n",
    "    title='Transformation Normal -> Secheresse par CycleGAN',\n",
    "    save_path=f\"{DRIVE_OUTPUTS}/evaluation/comparisons/cyclegan_normal_vs_drought.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resume\n",
    "\n",
    "**Observations :**\n",
    "- Le CycleGAN apprend a transformer les images normales en images seches\n",
    "- La coherence cyclique preserve la structure spatiale (routes, limites de parcelles)\n",
    "- La perte d'identite aide a preserver les teintes de couleur\n",
    "\n",
    "**Sauvegardes dans Drive :**\n",
    "- `cyclegan/checkpoints/` : checkpoints toutes les 10 epochs + final.pth\n",
    "- `cyclegan/generated_images/` : images A->B et B->A a chaque sauvegarde\n",
    "- `cyclegan/losses/loss_history.json` : historique complet des pertes\n",
    "\n",
    "**Prochaine etape :** Entrainer le modele de diffusion (DDPM) sur les images\n",
    "de secheresse pour generer de nouveaux echantillons synthetiques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
