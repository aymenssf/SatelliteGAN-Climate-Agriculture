{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Entrainement du Modele de Diffusion (DDPM)\n",
    "\n",
    "Ce notebook entraine un DDPM (Denoising Diffusion Probabilistic Model)\n",
    "pour generer des images satellites synthetiques de secheresse.\n",
    "\n",
    "**Pipeline :**\n",
    "1. Preparer les images du domaine secheresse (generees par CycleGAN ou simulees)\n",
    "2. Visualiser le processus de diffusion (ajout progressif de bruit)\n",
    "3. Initialiser le DDPM (U-Net + scheduler) avec sauvegarde Drive\n",
    "4. Entrainer (~4-6h sur GPU T4 Colab) avec auto-resume\n",
    "5. Generer des echantillons et evaluer la qualite visuelle\n",
    "6. Sauvegarder le modele final dans Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Configuration Google Drive pour sauvegarde outputs.\n",
    "Les notebooks restent sur GitHub, seuls les checkpoints/resultats vont dans Drive.\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import drive\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Montage Drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# Chemin racine pour les outputs uniquement\n",
    "DRIVE_OUTPUTS = \"/content/drive/MyDrive/SatelliteGAN-Outputs\"\n",
    "\n",
    "# Creation structure outputs\n",
    "for subdir in [\n",
    "    'data/eurosat', 'data/processed_drought',\n",
    "    'cyclegan/checkpoints', 'cyclegan/generated_images', 'cyclegan/losses',\n",
    "    'diffusion/checkpoints', 'diffusion/samples', 'diffusion/losses',\n",
    "    'evaluation/metrics', 'evaluation/comparisons', 'evaluation/figures',\n",
    "]:\n",
    "    os.makedirs(f\"{DRIVE_OUTPUTS}/{subdir}\", exist_ok=True)\n",
    "\n",
    "print(f\"Drive monte : {DRIVE_OUTPUTS}\")\n",
    "print(f\"Structure outputs creee\")\n",
    "\n",
    "# Clone du repo GitHub (code source)\n",
    "if not os.path.exists('/content/SatelliteGAN-Climate-Agriculture'):\n",
    "    !git clone https://github.com/aymenssf/SatelliteGAN-Climate-Agriculture.git /content/SatelliteGAN-Climate-Agriculture\n",
    "    !pip install -q -r /content/SatelliteGAN-Climate-Agriculture/requirements.txt\n",
    "\n",
    "%cd /content/SatelliteGAN-Climate-Agriculture\n",
    "sys.path.insert(0, '/content/SatelliteGAN-Climate-Agriculture')\n",
    "\n",
    "print(\"Code source charge depuis GitHub\")\n",
    "print(\"Outputs seront sauvegardes dans Drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from src.config import DEVICE, DIFFUSION, IMAGE_SIZE\n",
    "from src.dataset import get_agricultural_dataset, split_dataset\n",
    "from src.preprocessing import (\n",
    "    get_eval_transform, simulate_drought, tensor_to_numpy\n",
    ")\n",
    "from src.diffusion.train import DiffusionTrainer\n",
    "from src.evaluation.visualization import (\n",
    "    show_image_grid, show_comparison, plot_training_losses\n",
    ")\n",
    "\n",
    "print(f\"Device : {DEVICE}\")\n",
    "print(f\"Configuration DDPM : {DIFFUSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation des donnees\n",
    "\n",
    "On entraine le DDPM sur les images du domaine secheresse.\n",
    "\n",
    "Deux options :\n",
    "- **Option A** : Utiliser les images transformees par le CycleGAN (meilleur)\n",
    "- **Option B** : Utiliser les images de secheresse simulee (plus simple)\n",
    "\n",
    "On utilise l'option B par defaut. Pour l'option A, charger un checkpoint CycleGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Charger les images et appliquer la simulation de secheresse\n",
    "raw_transform = transforms.Resize(IMAGE_SIZE)\n",
    "raw_dataset = get_agricultural_dataset(transform=raw_transform)\n",
    "train_set, val_set, _ = split_dataset(raw_dataset)\n",
    "\n",
    "# Creer le dataset de secheresse\n",
    "eval_transform = get_eval_transform()\n",
    "\n",
    "def prepare_drought_dataset(dataset, transform, n_max=None):\n",
    "    \"\"\"Prepare les images de secheresse normalisees.\"\"\"\n",
    "    images = []\n",
    "    n = min(len(dataset), n_max) if n_max else len(dataset)\n",
    "\n",
    "    for i in range(n):\n",
    "        img, _ = dataset[i]\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img_pil = transforms.ToPILImage()(img)\n",
    "        else:\n",
    "            img_pil = img\n",
    "\n",
    "        # Appliquer la secheresse\n",
    "        drought_pil = simulate_drought(img_pil, severity=0.6)\n",
    "        img_tensor = transform(drought_pil)\n",
    "        images.append(img_tensor)\n",
    "\n",
    "    return torch.stack(images)\n",
    "\n",
    "print(\"Preparation des images de secheresse...\")\n",
    "train_drought = prepare_drought_dataset(train_set, eval_transform)\n",
    "print(f\"Dataset de secheresse : {train_drought.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser quelques echantillons du dataset d'entrainement\n",
    "show_image_grid(\n",
    "    train_drought[:16], n_cols=4,\n",
    "    title='Echantillons du dataset secheresse (entrainement DDPM)',\n",
    "    save_path=f\"{DRIVE_OUTPUTS}/evaluation/comparisons/ddpm_training_samples.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_dataset = TensorDataset(train_drought)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=DIFFUSION['batch_size'],\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(f\"Nombre de batches par epoch : {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation du processus de diffusion\n",
    "\n",
    "Avant d'entrainer, visualisons comment le bruit est ajoute progressivement.\n",
    "Le processus forward de diffusion ajoute du bruit gaussien a chaque timestep,\n",
    "jusqu'a obtenir du bruit pur a t=T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.diffusion.scheduler import LinearNoiseScheduler\n",
    "\n",
    "scheduler = LinearNoiseScheduler(\n",
    "    n_timesteps=DIFFUSION['n_timesteps'],\n",
    "    beta_start=DIFFUSION['beta_start'],\n",
    "    beta_end=DIFFUSION['beta_end']\n",
    ")\n",
    "\n",
    "# Prendre une image\n",
    "sample_img = train_drought[0:1]  # (1, 3, 64, 64)\n",
    "\n",
    "# Afficher a differents timesteps\n",
    "timesteps = [0, 50, 100, 250, 500, 750, 999]\n",
    "fig, axes = plt.subplots(1, len(timesteps), figsize=(3 * len(timesteps), 3))\n",
    "\n",
    "for i, t in enumerate(timesteps):\n",
    "    t_tensor = torch.tensor([t])\n",
    "    noisy, _ = scheduler.add_noise(sample_img, t_tensor)\n",
    "    img_np = tensor_to_numpy(noisy[0])\n",
    "    axes[i].imshow(img_np)\n",
    "    axes[i].set_title(f't = {t}', fontsize=11)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Processus forward de diffusion (ajout de bruit)',\n",
    "             fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{DRIVE_OUTPUTS}/evaluation/figures/ddpm_forward_process.png\",\n",
    "            dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialisation et entrainement\n",
    "\n",
    "Le `save_dir` pointe vers Google Drive pour que les checkpoints,\n",
    "samples generes et historique des pertes survivent aux deconnexions Colab.\n",
    "\n",
    "Si un checkpoint existe deja dans Drive, l'entrainement reprend\n",
    "automatiquement depuis le dernier checkpoint (auto-resume).\n",
    "\n",
    "**Sauvegarde automatique :**\n",
    "- Checkpoints tous les 25 epochs dans `Drive/SatelliteGAN-Outputs/diffusion/checkpoints/`\n",
    "- Samples generes dans `Drive/SatelliteGAN-Outputs/diffusion/samples/`\n",
    "- Historique pertes (JSON) dans `Drive/SatelliteGAN-Outputs/diffusion/losses/`\n",
    "\n",
    "**Auto-resume :** si l'entrainement est interrompu, relancer cette cellule.\n",
    "Le trainer detecte le dernier checkpoint et reprend automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le trainer avec sauvegarde Drive\n",
    "trainer = DiffusionTrainer(\n",
    "    save_dir=f\"{DRIVE_OUTPUTS}/diffusion\"  # Checkpoints, samples, pertes -> Drive\n",
    ")\n",
    "\n",
    "# Compter les parametres\n",
    "n_params = sum(p.numel() for p in trainer.model.parameters())\n",
    "print(f\"Parametres du U-Net : {n_params:,}\")\n",
    "print(f\"Sauvegarde : {DRIVE_OUTPUTS}/diffusion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "# Reduire n_epochs pour un test rapide (ex: 5-10 epochs)\n",
    "# Pour l'entrainement complet, utiliser DIFFUSION['n_epochs'] (150)\n",
    "N_EPOCHS = DIFFUSION['n_epochs']  # mettre 5 pour un test rapide\n",
    "\n",
    "# L'auto-resume detecte les checkpoints existants dans Drive.\n",
    "# Pour forcer une reprise depuis un checkpoint specifique :\n",
    "#   history = trainer.train(train_loader, n_epochs=N_EPOCHS,\n",
    "#                           resume_from=f\"{DRIVE_OUTPUTS}/diffusion/checkpoints/epoch_50.pth\")\n",
    "\n",
    "history = trainer.train(train_loader, n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Courbe de perte\n",
    "\n",
    "La perte du DDPM est le MSE entre le bruit reel et le bruit predit par le U-Net.\n",
    "Elle devrait diminuer regulierement au fil des epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les courbes de perte (sauvegardees dans Drive)\n",
    "plot_training_losses(\n",
    "    history,\n",
    "    title='DDPM - Perte de debruitage (MSE)',\n",
    "    save_path=f\"{DRIVE_OUTPUTS}/evaluation/figures/ddpm_losses.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generation d'images\n",
    "\n",
    "On genere des images en partant de bruit pur et en utilisant le processus\n",
    "reverse de diffusion. Le sampling rapide utilise 50 pas au lieu de 1000\n",
    "pour un temps de generation raisonnable. L'EMA ameliore la qualite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des images (sampling rapide avec EMA)\n",
    "print(\"Generation d'images (sampling rapide)...\")\n",
    "generated = trainer.generate(n_samples=16, use_ema=True, fast=True)\n",
    "\n",
    "show_image_grid(\n",
    "    generated.cpu(), n_cols=4,\n",
    "    title='Images generees par le DDPM (secheresse synthetique)',\n",
    "    save_path=f\"{DRIVE_OUTPUTS}/evaluation/comparisons/ddpm_generated.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avec les vraies images de secheresse\n",
    "show_comparison(\n",
    "    train_drought[:8].cpu(), generated[:8].cpu(),\n",
    "    n_samples=4,\n",
    "    labels=('Secheresse (dataset)', 'Secheresse (DDPM)'),\n",
    "    title='Comparaison : images reelles vs generees',\n",
    "    save_path=f\"{DRIVE_OUTPUTS}/evaluation/comparisons/ddpm_comparison.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume\n",
    "\n",
    "**Observations :**\n",
    "- Le DDPM apprend a generer des images satellites de secheresse\n",
    "- Les images generees montrent des textures et couleurs coherentes\n",
    "- Le sampling rapide (50 pas) produit des resultats raisonnables\n",
    "- L'EMA ameliore sensiblement la qualite des generations\n",
    "\n",
    "**Sauvegardes dans Drive :**\n",
    "- `diffusion/checkpoints/` : checkpoints toutes les 25 epochs + final.pth\n",
    "- `diffusion/samples/` : images generees a chaque sauvegarde\n",
    "- `diffusion/losses/loss_history.json` : historique complet des pertes\n",
    "- `evaluation/figures/ddpm_losses.png` : courbe de perte\n",
    "- `evaluation/comparisons/ddpm_generated.png` : grille d'images generees\n",
    "- `evaluation/comparisons/ddpm_comparison.png` : comparaison reel vs genere\n",
    "\n",
    "**Prochaine etape :** Evaluation quantitative avec SSIM, PSNR et FID\n",
    "dans le notebook `04_evaluation_results.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}