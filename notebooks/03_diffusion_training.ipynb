{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Entrainement du Modele de Diffusion (DDPM)\n",
    "\n",
    "Ce notebook entraine un DDPM (Denoising Diffusion Probabilistic Model)\n",
    "pour generer des images satellites synthetiques de secheresse.\n",
    "\n",
    "**Pipeline :**\n",
    "1. Preparer les images du domaine secheresse (generees par CycleGAN ou simulees)\n",
    "2. Initialiser le DDPM (U-Net + scheduler)\n",
    "3. Entrainer (~4-6h sur GPU T4 Colab)\n",
    "4. Generer des echantillons\n",
    "5. Evaluer la qualite visuelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (decommenter sur Colab)\n",
    "# !git clone https://github.com/aymenssf/SatelliteGAN-Climate-Agriculture.git\n",
    "# %cd SatelliteGAN-Climate-Agriculture\n",
    "# !pip install -q -r requirements.txt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd()))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from src.config import DEVICE, DIFFUSION, IMAGE_SIZE\n",
    "from src.dataset import get_agricultural_dataset, split_dataset\n",
    "from src.preprocessing import (\n",
    "    get_eval_transform, simulate_drought, tensor_to_numpy\n",
    ")\n",
    "from src.diffusion.train import DiffusionTrainer\n",
    "from src.evaluation.visualization import (\n",
    "    show_image_grid, show_comparison, plot_training_losses\n",
    ")\n",
    "\n",
    "print(f\"Device : {DEVICE}\")\n",
    "print(f\"Configuration DDPM : {DIFFUSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation des donnees\n",
    "\n",
    "On entraine le DDPM sur les images du domaine secheresse.\n",
    "\n",
    "Deux options :\n",
    "- **Option A** : Utiliser les images transformees par le CycleGAN (meilleur)\n",
    "- **Option B** : Utiliser les images de secheresse simulee (plus simple)\n",
    "\n",
    "On utilise l'option B par defaut. Pour l'option A, charger un checkpoint CycleGAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Charger les images et appliquer la simulation de secheresse\n",
    "raw_transform = transforms.Resize(IMAGE_SIZE)\n",
    "raw_dataset = get_agricultural_dataset(transform=raw_transform)\n",
    "train_set, val_set, _ = split_dataset(raw_dataset)\n",
    "\n",
    "# Creer le dataset de secheresse\n",
    "eval_transform = get_eval_transform()\n",
    "\n",
    "def prepare_drought_dataset(dataset, transform, n_max=None):\n",
    "    \"\"\"Prepare les images de secheresse normalisees.\"\"\"\n",
    "    images = []\n",
    "    n = min(len(dataset), n_max) if n_max else len(dataset)\n",
    "\n",
    "    for i in range(n):\n",
    "        img, _ = dataset[i]\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img_pil = transforms.ToPILImage()(img)\n",
    "        else:\n",
    "            img_pil = img\n",
    "\n",
    "        # Appliquer la secheresse\n",
    "        drought_pil = simulate_drought(img_pil, severity=0.6)\n",
    "        img_tensor = transform(drought_pil)\n",
    "        images.append(img_tensor)\n",
    "\n",
    "    return torch.stack(images)\n",
    "\n",
    "print(\"Preparation des images de secheresse...\")\n",
    "train_drought = prepare_drought_dataset(train_set, eval_transform)\n",
    "print(f\"Dataset de secheresse : {train_drought.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser quelques echantillons du dataset d'entrainement\n",
    "show_image_grid(train_drought[:16], n_cols=4,\n",
    "                title='Echantillons du dataset secheresse (entrainement DDPM)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "train_dataset = TensorDataset(train_drought)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=DIFFUSION['batch_size'],\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(f\"Nombre de batches par epoch : {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualisation du processus de diffusion\n",
    "\n",
    "Avant d'entrainer, visualisons comment le bruit est ajoute progressivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.diffusion.scheduler import LinearNoiseScheduler\n",
    "\n",
    "scheduler = LinearNoiseScheduler(\n",
    "    n_timesteps=DIFFUSION['n_timesteps'],\n",
    "    beta_start=DIFFUSION['beta_start'],\n",
    "    beta_end=DIFFUSION['beta_end']\n",
    ")\n",
    "\n",
    "# Prendre une image\n",
    "sample_img = train_drought[0:1]  # (1, 3, 64, 64)\n",
    "\n",
    "# Afficher a differents timesteps\n",
    "timesteps = [0, 50, 100, 250, 500, 750, 999]\n",
    "fig, axes = plt.subplots(1, len(timesteps), figsize=(3 * len(timesteps), 3))\n",
    "\n",
    "for i, t in enumerate(timesteps):\n",
    "    t_tensor = torch.tensor([t])\n",
    "    noisy, _ = scheduler.add_noise(sample_img, t_tensor)\n",
    "    img_np = tensor_to_numpy(noisy[0])\n",
    "    axes[i].imshow(img_np)\n",
    "    axes[i].set_title(f't = {t}', fontsize=11)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Processus forward de diffusion (ajout de bruit)',\n",
    "             fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialisation et entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer le trainer\n",
    "trainer = DiffusionTrainer()\n",
    "\n",
    "# Compter les parametres\n",
    "n_params = sum(p.numel() for p in trainer.model.parameters())\n",
    "print(f\"Parametres du U-Net : {n_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "# Reduire n_epochs pour un test rapide (ex: 5-10 epochs)\n",
    "# Pour l'entrainement complet, utiliser DIFFUSION['n_epochs'] (150)\n",
    "N_EPOCHS = DIFFUSION['n_epochs']  # mettre 5 pour un test rapide\n",
    "\n",
    "history = trainer.train(train_loader, n_epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Courbe de perte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_losses(history, title='DDPM - Perte de debruitage (MSE)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generation d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des images (sampling rapide)\n",
    "print(\"Generation d'images (sampling rapide)...\")\n",
    "generated = trainer.generate(n_samples=16, use_ema=True, fast=True)\n",
    "\n",
    "show_image_grid(\n",
    "    generated.cpu(), n_cols=4,\n",
    "    title='Images generees par le DDPM (secheresse synthetique)'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison avec les vraies images de secheresse\n",
    "show_comparison(\n",
    "    train_drought[:8].cpu(), generated[:8].cpu(),\n",
    "    n_samples=4,\n",
    "    labels=('Secheresse (dataset)', 'Secheresse (DDPM)'),\n",
    "    title='Comparaison : images reelles vs generees'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resume\n",
    "\n",
    "**Observations :**\n",
    "- Le DDPM apprend a generer des images satellites de secheresse\n",
    "- Les images generees montrent des textures et couleurs coherentes\n",
    "- Le sampling rapide (50 pas) produit des resultats raisonnables\n",
    "- L'EMA ameliore sensiblement la qualite des generations\n",
    "\n",
    "**Prochaine etape :** Evaluation quantitative avec SSIM, PSNR et FID."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
