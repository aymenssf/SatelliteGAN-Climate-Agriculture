{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Exploration des Donnees EuroSAT\n",
    "\n",
    "Ce notebook explore le dataset EuroSAT et les classes agricoles selectionnees.\n",
    "\n",
    "**Objectifs :**\n",
    "- Charger le dataset EuroSAT et filtrer les classes agricoles\n",
    "- Visualiser des echantillons de chaque classe\n",
    "- Analyser la distribution des classes\n",
    "- Tester la simulation de secheresse\n",
    "- Calculer et comparer les NDVI proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup (decommenter sur Colab)\n",
    "# !git clone https://github.com/aymenssf/SatelliteGAN-Climate-Agriculture.git\n",
    "# %cd SatelliteGAN-Climate-Agriculture\n",
    "# !pip install -q -r requirements.txt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd()))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from src.config import DEVICE, AGRICULTURAL_CLASSES, IMAGE_SIZE\n",
    "from src.dataset import get_agricultural_dataset, split_dataset, get_dataloader\n",
    "from src.preprocessing import (\n",
    "    get_train_transform, get_eval_transform,\n",
    "    simulate_drought, denormalize, tensor_to_numpy, compute_ndvi_proxy\n",
    ")\n",
    "\n",
    "print(f\"Device : {DEVICE}\")\n",
    "print(f\"Classes agricoles : {AGRICULTURAL_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le dataset avec les transformations d'evaluation (pas d'augmentation)\n",
    "dataset = get_agricultural_dataset(transform=get_eval_transform())\n",
    "\n",
    "print(f\"\\nNombre total d'images : {len(dataset)}\")\n",
    "print(f\"Classes : {dataset.class_names}\")\n",
    "print(f\"Taille d'une image : {dataset[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distribution des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les images par classe\n",
    "label_counts = Counter(dataset.labels)\n",
    "class_names = dataset.class_names\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "bars = ax.bar(\n",
    "    [class_names[i] for i in sorted(label_counts.keys())],\n",
    "    [label_counts[i] for i in sorted(label_counts.keys())],\n",
    "    color=['#4CAF50', '#8BC34A', '#FFC107', '#66BB6A']\n",
    ")\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "ax.set_title('Distribution des classes agricoles dans EuroSAT', fontsize=13)\n",
    "ax.set_ylabel('Nombre d\\'images')\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nResume :\")\n",
    "for idx in sorted(label_counts.keys()):\n",
    "    pct = label_counts[idx] / len(dataset) * 100\n",
    "    print(f\"  {class_names[idx]:25s} : {label_counts[idx]:5d} images ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisation d'echantillons par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher 4 images aleatoires par classe\n",
    "n_per_class = 4\n",
    "fig, axes = plt.subplots(len(class_names), n_per_class, figsize=(12, 3 * len(class_names)))\n",
    "\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    # Trouver les indices de cette classe\n",
    "    indices = [i for i, label in enumerate(dataset.labels) if label == class_idx]\n",
    "    # Echantillonner aleatoirement\n",
    "    sample_indices = np.random.choice(indices, n_per_class, replace=False)\n",
    "\n",
    "    for col, idx in enumerate(sample_indices):\n",
    "        img, label = dataset[idx]\n",
    "        img_np = tensor_to_numpy(img)\n",
    "        axes[class_idx, col].imshow(img_np)\n",
    "        axes[class_idx, col].axis('off')\n",
    "        if col == 0:\n",
    "            axes[class_idx, col].set_ylabel(class_name, fontsize=11, rotation=0,\n",
    "                                             labelpad=80, va='center')\n",
    "\n",
    "plt.suptitle('Echantillons par classe agricole', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulation de secheresse\n",
    "\n",
    "On applique notre transformation spectrale pour simuler l'effet de la secheresse.\n",
    "C'est une approximation grossiere -- le CycleGAN apprendra une transformation plus realiste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger des images SANS normalisation pour la simulation de secheresse\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# On prend quelques images brutes pour la demo\n",
    "raw_dataset = get_agricultural_dataset(transform=transforms.Resize(IMAGE_SIZE))\n",
    "\n",
    "# Afficher Normal vs Secheresse a differentes severites\n",
    "n_samples = 4\n",
    "severities = [0.3, 0.6, 0.9]\n",
    "indices = np.random.choice(len(raw_dataset), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, 1 + len(severities),\n",
    "                          figsize=(3 * (1 + len(severities)), 3 * n_samples))\n",
    "\n",
    "for row, idx in enumerate(indices):\n",
    "    img, label = raw_dataset[idx]\n",
    "    # img est un tensor ou PIL selon le transform\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img_pil = transforms.ToPILImage()(img)\n",
    "    else:\n",
    "        img_pil = img\n",
    "\n",
    "    # Image originale\n",
    "    axes[row, 0].imshow(img_pil)\n",
    "    axes[row, 0].axis('off')\n",
    "    if row == 0:\n",
    "        axes[row, 0].set_title('Original', fontsize=11)\n",
    "\n",
    "    # Images avec secheresse\n",
    "    for col, sev in enumerate(severities):\n",
    "        drought_img = simulate_drought(img_pil, severity=sev)\n",
    "        axes[row, col + 1].imshow(drought_img)\n",
    "        axes[row, col + 1].axis('off')\n",
    "        if row == 0:\n",
    "            axes[row, col + 1].set_title(f'Severite = {sev}', fontsize=11)\n",
    "\n",
    "plt.suptitle('Simulation de secheresse a differentes severites',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse NDVI proxy\n",
    "\n",
    "Le NDVI (Normalized Difference Vegetation Index) est un indicateur de la sante de la vegetation.\n",
    "On utilise un proxy base sur les bandes RGB car on n'a pas la bande NIR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparer NDVI entre images normales et secheresse\n",
    "eval_dataset = get_agricultural_dataset(transform=get_eval_transform())\n",
    "n_samples = 4\n",
    "indices = np.random.choice(len(eval_dataset), n_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, 4, figsize=(14, 3.5 * n_samples))\n",
    "col_titles = ['Normal', 'NDVI Normal', 'Secheresse simulee', 'NDVI Secheresse']\n",
    "\n",
    "for row, idx in enumerate(indices):\n",
    "    img_normal, _ = eval_dataset[idx]\n",
    "\n",
    "    # Simuler la secheresse sur la version PIL\n",
    "    raw_img, _ = raw_dataset[idx]\n",
    "    if isinstance(raw_img, torch.Tensor):\n",
    "        img_pil = transforms.ToPILImage()(raw_img)\n",
    "    else:\n",
    "        img_pil = raw_img\n",
    "    drought_pil = simulate_drought(img_pil, severity=0.6)\n",
    "\n",
    "    # Transformer la version secheresse en tensor normalise\n",
    "    eval_transform = get_eval_transform()\n",
    "    img_drought = eval_transform(drought_pil)\n",
    "\n",
    "    # Calculer NDVI\n",
    "    ndvi_normal = compute_ndvi_proxy(img_normal).numpy()\n",
    "    ndvi_drought = compute_ndvi_proxy(img_drought).numpy()\n",
    "\n",
    "    # Afficher\n",
    "    axes[row, 0].imshow(tensor_to_numpy(img_normal))\n",
    "    axes[row, 1].imshow(ndvi_normal, cmap='RdYlGn', vmin=-0.5, vmax=0.5)\n",
    "    axes[row, 2].imshow(tensor_to_numpy(img_drought))\n",
    "    axes[row, 3].imshow(ndvi_drought, cmap='RdYlGn', vmin=-0.5, vmax=0.5)\n",
    "\n",
    "    for col in range(4):\n",
    "        axes[row, col].axis('off')\n",
    "        if row == 0:\n",
    "            axes[row, col].set_title(col_titles[col], fontsize=11)\n",
    "\n",
    "    # Annoter les NDVI moyens\n",
    "    axes[row, 1].text(2, 5, f'moy={ndvi_normal.mean():.3f}',\n",
    "                       color='white', fontsize=9, fontweight='bold',\n",
    "                       bbox=dict(boxstyle='round', facecolor='black', alpha=0.5))\n",
    "    axes[row, 3].text(2, 5, f'moy={ndvi_drought.mean():.3f}',\n",
    "                       color='white', fontsize=9, fontweight='bold',\n",
    "                       bbox=dict(boxstyle='round', facecolor='black', alpha=0.5))\n",
    "\n",
    "plt.suptitle('Comparaison NDVI : Normal vs Secheresse simulee',\n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifier le split\n",
    "train_set, val_set, test_set = split_dataset(eval_dataset)\n",
    "\n",
    "print(f\"\\nTaille des ensembles :\")\n",
    "print(f\"  Train : {len(train_set)} images\")\n",
    "print(f\"  Val   : {len(val_set)} images\")\n",
    "print(f\"  Test  : {len(test_set)} images\")\n",
    "print(f\"  Total : {len(train_set) + len(val_set) + len(test_set)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Resume\n",
    "\n",
    "**Observations :**\n",
    "- Le dataset EuroSAT contient ~10k images pour les 4 classes agricoles\n",
    "- La simulation de secheresse modifie visuellement les images de maniere coherente\n",
    "- Le NDVI proxy diminue bien avec la severite de la secheresse\n",
    "- Le split 80/10/10 donne un ensemble d'entrainement suffisant\n",
    "\n",
    "**Prochaine etape :** Entrainer le CycleGAN pour apprendre une transformation\n",
    "normal -> secheresse plus realiste que notre simulation spectrale."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
